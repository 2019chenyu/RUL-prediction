{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "RandomState(2019)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,LSTM,Dropout,Activation,Bidirectional\n",
    "from keras.callbacks import ReduceLROnPlateau  #学习率自动变化\n",
    "\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 16,6\n",
    "plt.rcParams['xtick.color'] = 'w'  \n",
    "plt.rcParams['ytick.color'] = 'w'  \n",
    "mpl.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据导入和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_path = r'../data/processed_data/train_df.csv'\n",
    "test_df_path = r'../data/processed_data/test_df.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_df_path,index_col=0) #第一列作为index\n",
    "test_df = pd.read_csv(test_df_path,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20631 entries, 0 to 20630\n",
      "Data columns (total 28 columns):\n",
      "id            20631 non-null int64\n",
      "cycle         20631 non-null int64\n",
      "setting1      20631 non-null float64\n",
      "setting2      20631 non-null float64\n",
      "setting3      20631 non-null float64\n",
      "s1            20631 non-null float64\n",
      "s2            20631 non-null float64\n",
      "s3            20631 non-null float64\n",
      "s4            20631 non-null float64\n",
      "s5            20631 non-null float64\n",
      "s6            20631 non-null float64\n",
      "s7            20631 non-null float64\n",
      "s8            20631 non-null float64\n",
      "s9            20631 non-null float64\n",
      "s10           20631 non-null float64\n",
      "s11           20631 non-null float64\n",
      "s12           20631 non-null float64\n",
      "s13           20631 non-null float64\n",
      "s14           20631 non-null float64\n",
      "s15           20631 non-null float64\n",
      "s16           20631 non-null float64\n",
      "s17           20631 non-null float64\n",
      "s18           20631 non-null float64\n",
      "s19           20631 non-null float64\n",
      "s20           20631 non-null float64\n",
      "s21           20631 non-null float64\n",
      "RUL           20631 non-null int64\n",
      "cycle_norm    20631 non-null float64\n",
      "dtypes: float64(25), int64(3)\n",
      "memory usage: 4.6 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>130</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>130</td>\n",
       "      <td>0.00277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>130</td>\n",
       "      <td>0.00554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>130</td>\n",
       "      <td>0.00831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>130</td>\n",
       "      <td>0.01108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0   1      1  0.459770  0.166667       0.0  0.0  0.183735  0.406802  0.309757   \n",
       "1   1      2  0.609195  0.250000       0.0  0.0  0.283133  0.453019  0.352633   \n",
       "2   1      3  0.252874  0.750000       0.0  0.0  0.343373  0.369523  0.370527   \n",
       "3   1      4  0.540230  0.500000       0.0  0.0  0.343373  0.256159  0.331195   \n",
       "4   1      5  0.390805  0.333333       0.0  0.0  0.349398  0.257467  0.404625   \n",
       "\n",
       "    s5     ...           s14       s15  s16       s17  s18  s19       s20  \\\n",
       "0  0.0     ...      0.199608  0.363986  0.0  0.333333  0.0  0.0  0.713178   \n",
       "1  0.0     ...      0.162813  0.411312  0.0  0.333333  0.0  0.0  0.666667   \n",
       "2  0.0     ...      0.171793  0.357445  0.0  0.166667  0.0  0.0  0.627907   \n",
       "3  0.0     ...      0.174889  0.166603  0.0  0.333333  0.0  0.0  0.573643   \n",
       "4  0.0     ...      0.174734  0.402078  0.0  0.416667  0.0  0.0  0.589147   \n",
       "\n",
       "        s21  RUL  cycle_norm  \n",
       "0  0.724662  130     0.00000  \n",
       "1  0.731014  130     0.00277  \n",
       "2  0.621375  130     0.00554  \n",
       "3  0.662386  130     0.00831  \n",
       "4  0.704502  130     0.01108  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132160</td>\n",
       "      <td>0.308965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170090</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152751</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n",
       "1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n",
       "2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n",
       "3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n",
       "4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n",
       "\n",
       "    s5 ...        s14       s15  s16       s17  s18  s19       s20       s21  \\\n",
       "0  0.0 ...   0.132160  0.308965  0.0  0.333333  0.0  0.0  0.558140  0.661834   \n",
       "1  0.0 ...   0.204768  0.213159  0.0  0.416667  0.0  0.0  0.682171  0.686827   \n",
       "2  0.0 ...   0.155640  0.458638  0.0  0.416667  0.0  0.0  0.728682  0.721348   \n",
       "3  0.0 ...   0.170090  0.257022  0.0  0.250000  0.0  0.0  0.666667  0.662110   \n",
       "4  0.0 ...   0.152751  0.300885  0.0  0.166667  0.0  0.0  0.658915  0.716377   \n",
       "\n",
       "   cycle_norm  RUL  \n",
       "0     0.00000  142  \n",
       "1     0.00277  141  \n",
       "2     0.00554  140  \n",
       "3     0.00831  139  \n",
       "4     0.01108  138  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    s1        s2        s3        s4   s5   s6        s7        s8        s9  \\\n",
      "0  0.0  0.183735  0.406802  0.309757  0.0  1.0  0.726248  0.242424  0.109755   \n",
      "1  0.0  0.283133  0.453019  0.352633  0.0  1.0  0.628019  0.212121  0.100242   \n",
      "2  0.0  0.343373  0.369523  0.370527  0.0  1.0  0.710145  0.272727  0.140043   \n",
      "3  0.0  0.343373  0.256159  0.331195  0.0  1.0  0.740741  0.318182  0.124518   \n",
      "4  0.0  0.349398  0.257467  0.404625  0.0  1.0  0.668277  0.242424  0.149960   \n",
      "\n",
      "   s10    ...          s12       s13       s14       s15  s16       s17  s18  \\\n",
      "0  0.0    ...     0.633262  0.205882  0.199608  0.363986  0.0  0.333333  0.0   \n",
      "1  0.0    ...     0.765458  0.279412  0.162813  0.411312  0.0  0.333333  0.0   \n",
      "2  0.0    ...     0.795309  0.220588  0.171793  0.357445  0.0  0.166667  0.0   \n",
      "3  0.0    ...     0.889126  0.294118  0.174889  0.166603  0.0  0.333333  0.0   \n",
      "4  0.0    ...     0.746269  0.235294  0.174734  0.402078  0.0  0.416667  0.0   \n",
      "\n",
      "   s19       s20       s21  \n",
      "0  0.0  0.713178  0.724662  \n",
      "1  0.0  0.666667  0.731014  \n",
      "2  0.0  0.627907  0.621375  \n",
      "3  0.0  0.573643  0.662386  \n",
      "4  0.0  0.589147  0.704502  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.iloc[:,5:26]\n",
    "y_train = train_df.iloc[:,-2]\n",
    "print(X_train.head())\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    s1        s2        s3        s4   s5   s6        s7        s8        s9  \\\n",
      "0  0.0  0.545181  0.310661  0.269413  0.0  1.0  0.652174  0.212121  0.127614   \n",
      "1  0.0  0.150602  0.379551  0.222316  0.0  1.0  0.805153  0.166667  0.146684   \n",
      "2  0.0  0.376506  0.346632  0.322248  0.0  1.0  0.685990  0.227273  0.158081   \n",
      "3  0.0  0.370482  0.285154  0.408001  0.0  1.0  0.679549  0.196970  0.105717   \n",
      "4  0.0  0.391566  0.352082  0.332039  0.0  1.0  0.694042  0.166667  0.102396   \n",
      "\n",
      "   s10    ...          s12       s13       s14       s15  s16       s17  s18  \\\n",
      "0  0.0    ...     0.646055  0.220588  0.132160  0.308965  0.0  0.333333  0.0   \n",
      "1  0.0    ...     0.739872  0.264706  0.204768  0.213159  0.0  0.416667  0.0   \n",
      "2  0.0    ...     0.699360  0.220588  0.155640  0.458638  0.0  0.416667  0.0   \n",
      "3  0.0    ...     0.573561  0.250000  0.170090  0.257022  0.0  0.250000  0.0   \n",
      "4  0.0    ...     0.737740  0.220588  0.152751  0.300885  0.0  0.166667  0.0   \n",
      "\n",
      "   s19       s20       s21  \n",
      "0  0.0  0.558140  0.661834  \n",
      "1  0.0  0.682171  0.686827  \n",
      "2  0.0  0.728682  0.721348  \n",
      "3  0.0  0.666667  0.662110  \n",
      "4  0.0  0.658915  0.716377  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.iloc[:,5:26]\n",
    "y_test = test_df.iloc[:,-1]#注意，当前用的数据中测试集的RUL是最后一列!!!\n",
    "print(X_test.head())\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 21)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=17,random_state=2019,whiten=False)\n",
    "X_all = np.concatenate((X_train,X_test))\n",
    "pca.fit(X_all,y=None)\n",
    "X_all = pca.transform(X_all)\n",
    "X_train = X_all[0:len(X_train)]\n",
    "X_test = X_all[len(X_train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据标准化**\n",
    "\n",
    "**注意：lstm-v1.ipynb使用归一化，效果不如标准化好。因为归一化受异常点的影响太大了。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#min_max_scalar = preprocessing.MinMaxScaler()\\nstandard_scalar = preprocessing.StandardScaler()\\nX_train = standard_scalar.fit_transform(X_train)\\nX_test = standard_scalar.fit_transform(X_test)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#min_max_scalar = preprocessing.MinMaxScaler()\n",
    "standard_scalar = preprocessing.StandardScaler()\n",
    "X_train = standard_scalar.fit_transform(X_train)\n",
    "X_test = standard_scalar.fit_transform(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, train_size=0.7,random_state=2019,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14441, 17) (14441,) (6190, 17) (6190,) (13096, 17) (13096,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape,\n",
    "      y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在X_train, y_train, X_test, y_test已经准备好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到LSTM（）层必须指定输入的形状。而且每个LSTM层的输入必须是三维的。这输入的三个维度是：\n",
    "\n",
    "- samples。一个序列是一个样本。批次由一个或多个样本组成。\n",
    "\n",
    "- timesteps。一个时间步代表样本中的一个观察点。timesteps可以理解为循环神经网络认为每个输入数据与前多少个连续输入的数据有联系\n",
    "\n",
    "- features。一个特征是在一个时间步长的观察得到的。\n",
    "- 学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:14441\n",
      "Number of validation samples:6190\n",
      "Number of testing samples:13096\n",
      "(14441, 1, 17) (14441, 1) (13096, 1, 17) (13096, 1)\n"
     ]
    }
   ],
   "source": [
    "# 数据改造成LSTM输入的格式\n",
    "\n",
    "timesteps = 1\n",
    "\n",
    "samples_num_train = X_train.shape[0]//timesteps\n",
    "samples_num_valid = X_valid.shape[0]//timesteps\n",
    "samples_num_test = X_test.shape[0]//timesteps\n",
    "\n",
    "print(\"Number of training samples:{}\".format(samples_num_train))\n",
    "print(\"Number of validation samples:{}\".format(samples_num_valid))\n",
    "print(\"Number of testing samples:{}\".format(samples_num_test))\n",
    "\n",
    "X_train = X_train.reshape((samples_num_train,timesteps,X_train.shape[1]))\n",
    "X_valid = X_valid.reshape((samples_num_valid,timesteps,X_valid.shape[1]))\n",
    "X_test = X_test.reshape((samples_num_test,timesteps,X_test.shape[1]))\n",
    "\n",
    "y_train = y_train.reshape((samples_num_train,timesteps))\n",
    "y_valid = y_valid.reshape((samples_num_valid,timesteps))\n",
    "y_test = y_test.reshape((samples_num_test,timesteps))\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Bidirectional(LSTM(\n",
    "        50,\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        return_sequences=False)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "#model.add(LSTM(40)\n",
    "#model.add(Activation('tanh'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('tanh')) #不能用relu,否则容易梯度爆炸\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')#rmsprop和adam差别不大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以调节的地方：\n",
    "- 训练时是否shuffle\n",
    "- LSTM神经元个数\n",
    "- timesteps\n",
    "- LSTM层数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14441 samples, validate on 6190 samples\n",
      "Epoch 1/100\n",
      "14441/14441 [==============================] - 2s 152us/step - loss: 8779.8854 - val_loss: 7201.7474\n",
      "Epoch 2/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 6173.3545 - val_loss: 5582.4010\n",
      "Epoch 3/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 4999.0876 - val_loss: 4628.2945\n",
      "Epoch 4/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 4164.7003 - val_loss: 3882.3230\n",
      "Epoch 5/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 3504.2812 - val_loss: 3281.9744\n",
      "Epoch 6/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 2965.6953 - val_loss: 2784.4522\n",
      "Epoch 7/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 2516.3669 - val_loss: 2365.7243\n",
      "Epoch 8/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 2137.2833 - val_loss: 2011.6346\n",
      "Epoch 9/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 1818.2676 - val_loss: 1713.1688\n",
      "Epoch 10/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 1550.3847 - val_loss: 1463.4651\n",
      "Epoch 11/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 1328.0175 - val_loss: 1256.6168\n",
      "Epoch 12/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 1144.6656 - val_loss: 1086.8428\n",
      "Epoch 13/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 993.8921 - val_loss: 948.7110\n",
      "Epoch 14/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 873.0221 - val_loss: 836.6359\n",
      "Epoch 15/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 773.7933 - val_loss: 745.8732\n",
      "Epoch 16/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 694.6034 - val_loss: 671.9571\n",
      "Epoch 17/100\n",
      "14441/14441 [==============================] - 1s 39us/step - loss: 631.1884 - val_loss: 612.5687\n",
      "Epoch 18/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 579.9992 - val_loss: 565.1264\n",
      "Epoch 19/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 540.0918 - val_loss: 526.7153\n",
      "Epoch 20/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 507.1053 - val_loss: 496.6100\n",
      "Epoch 21/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 480.9653 - val_loss: 472.1472\n",
      "Epoch 22/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 460.3234 - val_loss: 452.7526\n",
      "Epoch 23/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 444.9434 - val_loss: 437.6331\n",
      "Epoch 24/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 432.0899 - val_loss: 425.4732\n",
      "Epoch 25/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 420.4271 - val_loss: 415.7162\n",
      "Epoch 26/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 413.8271 - val_loss: 408.0779\n",
      "Epoch 27/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 407.1098 - val_loss: 402.5496\n",
      "Epoch 28/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 402.5090 - val_loss: 397.2146\n",
      "Epoch 29/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 396.2870 - val_loss: 393.1273\n",
      "Epoch 30/100\n",
      "14441/14441 [==============================] - 1s 39us/step - loss: 392.6815 - val_loss: 389.3381\n",
      "Epoch 31/100\n",
      "14441/14441 [==============================] - 1s 40us/step - loss: 388.9063 - val_loss: 386.9073\n",
      "Epoch 32/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 387.5199 - val_loss: 384.5381\n",
      "Epoch 33/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 385.8649 - val_loss: 382.2369\n",
      "Epoch 34/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 382.8338 - val_loss: 381.9948\n",
      "Epoch 35/100\n",
      "14441/14441 [==============================] - 1s 39us/step - loss: 383.7900 - val_loss: 380.4766\n",
      "Epoch 36/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 382.0625 - val_loss: 379.3325\n",
      "Epoch 37/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 380.4172 - val_loss: 378.8949\n",
      "Epoch 38/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 379.8920 - val_loss: 378.3837\n",
      "Epoch 39/100\n",
      "14441/14441 [==============================] - 1s 39us/step - loss: 379.6630 - val_loss: 377.5458\n",
      "Epoch 40/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 380.1890 - val_loss: 377.2894\n",
      "Epoch 41/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 379.8732 - val_loss: 377.3721\n",
      "Epoch 42/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 379.3047 - val_loss: 376.8780\n",
      "Epoch 43/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 377.4793 - val_loss: 376.6848\n",
      "Epoch 44/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 378.9176 - val_loss: 376.4626\n",
      "Epoch 45/100\n",
      "14441/14441 [==============================] - 1s 39us/step - loss: 379.3734 - val_loss: 376.0979\n",
      "Epoch 46/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 378.8933 - val_loss: 375.9626\n",
      "Epoch 47/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 376.7503 - val_loss: 375.6471\n",
      "Epoch 48/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 376.5114 - val_loss: 375.7048\n",
      "Epoch 49/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 377.7436 - val_loss: 375.4594\n",
      "Epoch 50/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 376.9352 - val_loss: 375.2737\n",
      "Epoch 51/100\n",
      "14441/14441 [==============================] - 1s 39us/step - loss: 375.9895 - val_loss: 375.0334\n",
      "Epoch 52/100\n",
      "14441/14441 [==============================] - 1s 39us/step - loss: 376.7644 - val_loss: 374.7749\n",
      "Epoch 53/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 375.4219 - val_loss: 374.4942\n",
      "Epoch 54/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 376.1543 - val_loss: 374.5140\n",
      "Epoch 55/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 375.6382 - val_loss: 374.3603\n",
      "Epoch 56/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 376.5850 - val_loss: 374.4696\n",
      "Epoch 57/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 375.4060 - val_loss: 374.2616\n",
      "Epoch 58/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 375.3369 - val_loss: 373.7474\n",
      "Epoch 59/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 376.0632 - val_loss: 373.9549\n",
      "Epoch 60/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 374.1856 - val_loss: 373.7499\n",
      "Epoch 61/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 374.2990 - val_loss: 373.1695\n",
      "Epoch 62/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 374.4594 - val_loss: 373.6103\n",
      "Epoch 63/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 374.7925 - val_loss: 372.9629\n",
      "Epoch 64/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 374.7266 - val_loss: 373.0132\n",
      "Epoch 65/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 372.9680 - val_loss: 372.6446\n",
      "Epoch 66/100\n",
      "14441/14441 [==============================] - 1s 39us/step - loss: 374.3602 - val_loss: 372.7597\n",
      "Epoch 67/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 372.9170 - val_loss: 372.3897\n",
      "Epoch 68/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 373.2509 - val_loss: 372.0857\n",
      "Epoch 69/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 373.4060 - val_loss: 372.2914\n",
      "Epoch 70/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 372.0861 - val_loss: 372.0415\n",
      "Epoch 71/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 372.8601 - val_loss: 371.5184\n",
      "Epoch 72/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 372.2423 - val_loss: 371.3037\n",
      "Epoch 73/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 372.1187 - val_loss: 371.1457\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14441/14441 [==============================] - 1s 38us/step - loss: 370.9011 - val_loss: 371.2861\n",
      "Epoch 75/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 370.6935 - val_loss: 370.9496\n",
      "Epoch 76/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 372.0700 - val_loss: 370.4265\n",
      "Epoch 77/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 370.3195 - val_loss: 370.2968\n",
      "Epoch 78/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 370.1719 - val_loss: 370.2486\n",
      "Epoch 79/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 370.9311 - val_loss: 370.3071\n",
      "Epoch 80/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 370.9365 - val_loss: 369.8887\n",
      "Epoch 81/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 371.7037 - val_loss: 370.0415\n",
      "Epoch 82/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 370.1880 - val_loss: 369.5716\n",
      "Epoch 83/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 369.7811 - val_loss: 369.4406\n",
      "Epoch 84/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 369.7174 - val_loss: 369.1758\n",
      "Epoch 85/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 369.6215 - val_loss: 369.1789\n",
      "Epoch 86/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 368.3581 - val_loss: 368.6408\n",
      "Epoch 87/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 366.5679 - val_loss: 368.8115\n",
      "Epoch 88/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 369.5619 - val_loss: 368.7144\n",
      "Epoch 89/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 367.1163 - val_loss: 368.3360\n",
      "Epoch 90/100\n",
      "14441/14441 [==============================] - 1s 41us/step - loss: 369.1287 - val_loss: 368.3358\n",
      "Epoch 91/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 368.2230 - val_loss: 368.1375\n",
      "Epoch 92/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 368.4160 - val_loss: 367.6303\n",
      "Epoch 93/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 367.9648 - val_loss: 367.2760\n",
      "Epoch 94/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 367.6420 - val_loss: 367.6138\n",
      "Epoch 95/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 366.4001 - val_loss: 367.7231\n",
      "Epoch 96/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 365.8919 - val_loss: 367.4128\n",
      "Epoch 97/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 367.9028 - val_loss: 367.0311\n",
      "Epoch 98/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 366.3630 - val_loss: 366.8570\n",
      "Epoch 99/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 367.6098 - val_loss: 366.5447\n",
      "Epoch 100/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 365.4494 - val_loss: 366.9722\n",
      "Training time: 2.619 minutes\n"
     ]
    }
   ],
   "source": [
    "#10个epoch loss不下降，就降低学习率\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, mode='auto')\n",
    "start_time = time.clock()\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1,\n",
    "    shuffle=False)  #shuffle=False比True时测试集rmse降低了1\n",
    "end_time = time.clock()\n",
    "print(\"Training time: {:.4} minutes\".format((end_time - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val') \n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions,targets):\n",
    "    return np.sqrt(((predictions-targets)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rmse = rmse(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rmse: 19.116730556129017\n",
      "Validation rmse: 19.15651717740319\n",
      "Test rmse: 57.19613601600581\n"
     ]
    }
   ],
   "source": [
    "print(\"Train rmse: {}\".format(np.sqrt(history.history['loss'][-1])))\n",
    "print(\"Validation rmse: {}\".format(np.sqrt(history.history['val_loss'][-1])))\n",
    "print(\"Test rmse: {}\".format(my_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加入PCA降维和自动学习率下降后，精度大大提升**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_2 (Bidirection (None, 100)               27200     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 32,301\n",
      "Trainable params: 32,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "689px",
    "left": "25px",
    "top": "180px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "931px",
    "right": "20px",
    "top": "21px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
