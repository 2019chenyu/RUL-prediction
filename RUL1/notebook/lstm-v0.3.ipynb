{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "RandomState(2019)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,LSTM,Dropout,Activation,Bidirectional\n",
    "from keras.callbacks import ReduceLROnPlateau  #学习率自动变化\n",
    "\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 16,6\n",
    "plt.rcParams['xtick.color'] = 'w'  \n",
    "plt.rcParams['ytick.color'] = 'w'  \n",
    "mpl.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据导入和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_path = r'../data/processed_data/train_df.csv'\n",
    "test_df_path = r'../data/processed_data/test_df.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_df_path,index_col=0) #第一列作为index\n",
    "test_df = pd.read_csv(test_df_path,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20631 entries, 0 to 20630\n",
      "Data columns (total 28 columns):\n",
      "id            20631 non-null int64\n",
      "cycle         20631 non-null int64\n",
      "setting1      20631 non-null float64\n",
      "setting2      20631 non-null float64\n",
      "setting3      20631 non-null float64\n",
      "s1            20631 non-null float64\n",
      "s2            20631 non-null float64\n",
      "s3            20631 non-null float64\n",
      "s4            20631 non-null float64\n",
      "s5            20631 non-null float64\n",
      "s6            20631 non-null float64\n",
      "s7            20631 non-null float64\n",
      "s8            20631 non-null float64\n",
      "s9            20631 non-null float64\n",
      "s10           20631 non-null float64\n",
      "s11           20631 non-null float64\n",
      "s12           20631 non-null float64\n",
      "s13           20631 non-null float64\n",
      "s14           20631 non-null float64\n",
      "s15           20631 non-null float64\n",
      "s16           20631 non-null float64\n",
      "s17           20631 non-null float64\n",
      "s18           20631 non-null float64\n",
      "s19           20631 non-null float64\n",
      "s20           20631 non-null float64\n",
      "s21           20631 non-null float64\n",
      "RUL           20631 non-null int64\n",
      "cycle_norm    20631 non-null float64\n",
      "dtypes: float64(25), int64(3)\n",
      "memory usage: 4.6 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199608</td>\n",
       "      <td>0.363986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>130</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162813</td>\n",
       "      <td>0.411312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>130</td>\n",
       "      <td>0.00277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171793</td>\n",
       "      <td>0.357445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>130</td>\n",
       "      <td>0.00554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174889</td>\n",
       "      <td>0.166603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>130</td>\n",
       "      <td>0.00831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174734</td>\n",
       "      <td>0.402078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>130</td>\n",
       "      <td>0.01108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0   1      1  0.459770  0.166667       0.0  0.0  0.183735  0.406802  0.309757   \n",
       "1   1      2  0.609195  0.250000       0.0  0.0  0.283133  0.453019  0.352633   \n",
       "2   1      3  0.252874  0.750000       0.0  0.0  0.343373  0.369523  0.370527   \n",
       "3   1      4  0.540230  0.500000       0.0  0.0  0.343373  0.256159  0.331195   \n",
       "4   1      5  0.390805  0.333333       0.0  0.0  0.349398  0.257467  0.404625   \n",
       "\n",
       "    s5     ...           s14       s15  s16       s17  s18  s19       s20  \\\n",
       "0  0.0     ...      0.199608  0.363986  0.0  0.333333  0.0  0.0  0.713178   \n",
       "1  0.0     ...      0.162813  0.411312  0.0  0.333333  0.0  0.0  0.666667   \n",
       "2  0.0     ...      0.171793  0.357445  0.0  0.166667  0.0  0.0  0.627907   \n",
       "3  0.0     ...      0.174889  0.166603  0.0  0.333333  0.0  0.0  0.573643   \n",
       "4  0.0     ...      0.174734  0.402078  0.0  0.416667  0.0  0.0  0.589147   \n",
       "\n",
       "        s21  RUL  cycle_norm  \n",
       "0  0.724662  130     0.00000  \n",
       "1  0.731014  130     0.00277  \n",
       "2  0.621375  130     0.00554  \n",
       "3  0.662386  130     0.00831  \n",
       "4  0.704502  130     0.01108  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132160</td>\n",
       "      <td>0.308965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170090</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152751</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n",
       "1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n",
       "2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n",
       "3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n",
       "4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n",
       "\n",
       "    s5 ...        s14       s15  s16       s17  s18  s19       s20       s21  \\\n",
       "0  0.0 ...   0.132160  0.308965  0.0  0.333333  0.0  0.0  0.558140  0.661834   \n",
       "1  0.0 ...   0.204768  0.213159  0.0  0.416667  0.0  0.0  0.682171  0.686827   \n",
       "2  0.0 ...   0.155640  0.458638  0.0  0.416667  0.0  0.0  0.728682  0.721348   \n",
       "3  0.0 ...   0.170090  0.257022  0.0  0.250000  0.0  0.0  0.666667  0.662110   \n",
       "4  0.0 ...   0.152751  0.300885  0.0  0.166667  0.0  0.0  0.658915  0.716377   \n",
       "\n",
       "   cycle_norm  RUL  \n",
       "0     0.00000  142  \n",
       "1     0.00277  141  \n",
       "2     0.00554  140  \n",
       "3     0.00831  139  \n",
       "4     0.01108  138  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    s1        s2        s3        s4   s5   s6        s7        s8        s9  \\\n",
      "0  0.0  0.183735  0.406802  0.309757  0.0  1.0  0.726248  0.242424  0.109755   \n",
      "1  0.0  0.283133  0.453019  0.352633  0.0  1.0  0.628019  0.212121  0.100242   \n",
      "2  0.0  0.343373  0.369523  0.370527  0.0  1.0  0.710145  0.272727  0.140043   \n",
      "3  0.0  0.343373  0.256159  0.331195  0.0  1.0  0.740741  0.318182  0.124518   \n",
      "4  0.0  0.349398  0.257467  0.404625  0.0  1.0  0.668277  0.242424  0.149960   \n",
      "\n",
      "   s10    ...          s12       s13       s14       s15  s16       s17  s18  \\\n",
      "0  0.0    ...     0.633262  0.205882  0.199608  0.363986  0.0  0.333333  0.0   \n",
      "1  0.0    ...     0.765458  0.279412  0.162813  0.411312  0.0  0.333333  0.0   \n",
      "2  0.0    ...     0.795309  0.220588  0.171793  0.357445  0.0  0.166667  0.0   \n",
      "3  0.0    ...     0.889126  0.294118  0.174889  0.166603  0.0  0.333333  0.0   \n",
      "4  0.0    ...     0.746269  0.235294  0.174734  0.402078  0.0  0.416667  0.0   \n",
      "\n",
      "   s19       s20       s21  \n",
      "0  0.0  0.713178  0.724662  \n",
      "1  0.0  0.666667  0.731014  \n",
      "2  0.0  0.627907  0.621375  \n",
      "3  0.0  0.573643  0.662386  \n",
      "4  0.0  0.589147  0.704502  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.iloc[:,5:26]\n",
    "y_train = train_df.iloc[:,-2]\n",
    "print(X_train.head())\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    s1        s2        s3        s4   s5   s6        s7        s8        s9  \\\n",
      "0  0.0  0.545181  0.310661  0.269413  0.0  1.0  0.652174  0.212121  0.127614   \n",
      "1  0.0  0.150602  0.379551  0.222316  0.0  1.0  0.805153  0.166667  0.146684   \n",
      "2  0.0  0.376506  0.346632  0.322248  0.0  1.0  0.685990  0.227273  0.158081   \n",
      "3  0.0  0.370482  0.285154  0.408001  0.0  1.0  0.679549  0.196970  0.105717   \n",
      "4  0.0  0.391566  0.352082  0.332039  0.0  1.0  0.694042  0.166667  0.102396   \n",
      "\n",
      "   s10    ...          s12       s13       s14       s15  s16       s17  s18  \\\n",
      "0  0.0    ...     0.646055  0.220588  0.132160  0.308965  0.0  0.333333  0.0   \n",
      "1  0.0    ...     0.739872  0.264706  0.204768  0.213159  0.0  0.416667  0.0   \n",
      "2  0.0    ...     0.699360  0.220588  0.155640  0.458638  0.0  0.416667  0.0   \n",
      "3  0.0    ...     0.573561  0.250000  0.170090  0.257022  0.0  0.250000  0.0   \n",
      "4  0.0    ...     0.737740  0.220588  0.152751  0.300885  0.0  0.166667  0.0   \n",
      "\n",
      "   s19       s20       s21  \n",
      "0  0.0  0.558140  0.661834  \n",
      "1  0.0  0.682171  0.686827  \n",
      "2  0.0  0.728682  0.721348  \n",
      "3  0.0  0.666667  0.662110  \n",
      "4  0.0  0.658915  0.716377  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.iloc[:,5:26]\n",
    "y_test = test_df.iloc[:,-1]#注意，当前用的数据中测试集的RUL是最后一列!!!\n",
    "print(X_test.head())\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 21)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=17,random_state=2019,whiten=False)\n",
    "X_all = np.concatenate((X_train,X_test))\n",
    "pca.fit(X_all,y=None)\n",
    "X_all = pca.transform(X_all)\n",
    "X_train = X_all[0:len(X_train)]\n",
    "X_test = X_all[len(X_train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据标准化**\n",
    "\n",
    "**注意：lstm-v1.ipynb使用归一化，效果不如标准化好。因为归一化受异常点的影响太大了。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#min_max_scalar = preprocessing.MinMaxScaler()\\nstandard_scalar = preprocessing.StandardScaler()\\nX_train = standard_scalar.fit_transform(X_train)\\nX_test = standard_scalar.fit_transform(X_test)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#min_max_scalar = preprocessing.MinMaxScaler()\n",
    "standard_scalar = preprocessing.StandardScaler()\n",
    "X_train = standard_scalar.fit_transform(X_train)\n",
    "X_test = standard_scalar.fit_transform(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, train_size=0.7,random_state=2019,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14441, 17) (14441,) (6190, 17) (6190,) (13096, 17) (13096,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape,\n",
    "      y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在X_train, y_train, X_test, y_test已经准备好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到LSTM（）层必须指定输入的形状。而且每个LSTM层的输入必须是三维的。这输入的三个维度是：\n",
    "\n",
    "- samples。一个序列是一个样本。批次由一个或多个样本组成。\n",
    "\n",
    "- timesteps。一个时间步代表样本中的一个观察点。timesteps可以理解为循环神经网络认为每个输入数据与前多少个连续输入的数据有联系\n",
    "\n",
    "- features。一个特征是在一个时间步长的观察得到的。\n",
    "- 学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:14441\n",
      "Number of validation samples:6190\n",
      "Number of testing samples:13096\n",
      "(14441, 1, 17) (14441, 1) (13096, 1, 17) (13096, 1)\n"
     ]
    }
   ],
   "source": [
    "# 数据改造成LSTM输入的格式\n",
    "\n",
    "timesteps = 1\n",
    "\n",
    "samples_num_train = X_train.shape[0]//timesteps\n",
    "samples_num_valid = X_valid.shape[0]//timesteps\n",
    "samples_num_test = X_test.shape[0]//timesteps\n",
    "\n",
    "print(\"Number of training samples:{}\".format(samples_num_train))\n",
    "print(\"Number of validation samples:{}\".format(samples_num_valid))\n",
    "print(\"Number of testing samples:{}\".format(samples_num_test))\n",
    "\n",
    "X_train = X_train.reshape((samples_num_train,timesteps,X_train.shape[1]))\n",
    "X_valid = X_valid.reshape((samples_num_valid,timesteps,X_valid.shape[1]))\n",
    "X_test = X_test.reshape((samples_num_test,timesteps,X_test.shape[1]))\n",
    "\n",
    "y_train = y_train.reshape((samples_num_train,timesteps))\n",
    "y_valid = y_valid.reshape((samples_num_valid,timesteps))\n",
    "y_test = y_test.reshape((samples_num_test,timesteps))\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Bidirectional(LSTM(\n",
    "        50,\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        return_sequences=False)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "#model.add(LSTM(40)\n",
    "#model.add(Activation('tanh'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('tanh')) #不能用relu,否则容易梯度爆炸\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')#rmsprop和adam差别不大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以调节的地方：\n",
    "- 训练时是否shuffle\n",
    "- LSTM神经元个数\n",
    "- timesteps\n",
    "- LSTM层数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14441 samples, validate on 6190 samples\n",
      "Epoch 1/100\n",
      "14441/14441 [==============================] - 2s 154us/step - loss: 8747.1277 - val_loss: 7162.0820\n",
      "Epoch 2/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 6137.0807 - val_loss: 5548.5040\n",
      "Epoch 3/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 4967.6364 - val_loss: 4598.5927\n",
      "Epoch 4/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 4137.8743 - val_loss: 3857.0847\n",
      "Epoch 5/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 3481.2669 - val_loss: 3260.1978\n",
      "Epoch 6/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 2945.8652 - val_loss: 2765.6305\n",
      "Epoch 7/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 2498.2287 - val_loss: 2349.0526\n",
      "Epoch 8/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 2122.0390 - val_loss: 1997.0868\n",
      "Epoch 9/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 1805.1679 - val_loss: 1700.7308\n",
      "Epoch 10/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 1539.3337 - val_loss: 1453.0900\n",
      "Epoch 11/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 1318.1874 - val_loss: 1248.2736\n",
      "Epoch 12/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 1137.7965 - val_loss: 1080.4306\n",
      "Epoch 13/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 988.6122 - val_loss: 943.3647\n",
      "Epoch 14/100\n",
      "14441/14441 [==============================] - 1s 40us/step - loss: 868.1621 - val_loss: 832.5332\n",
      "Epoch 15/100\n",
      "14441/14441 [==============================] - 1s 40us/step - loss: 770.3182 - val_loss: 742.3995\n",
      "Epoch 16/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 692.2127 - val_loss: 669.5764\n",
      "Epoch 17/100\n",
      "14441/14441 [==============================] - 1s 41us/step - loss: 628.9589 - val_loss: 610.8804\n",
      "Epoch 18/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 578.8156 - val_loss: 563.6532\n",
      "Epoch 19/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 537.3224 - val_loss: 525.7589\n",
      "Epoch 20/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 506.2645 - val_loss: 495.8458\n",
      "Epoch 21/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 481.4187 - val_loss: 471.6484\n",
      "Epoch 22/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 459.8087 - val_loss: 452.3417\n",
      "Epoch 23/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 445.1613 - val_loss: 437.5271\n",
      "Epoch 24/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 432.3300 - val_loss: 425.3451\n",
      "Epoch 25/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 422.7042 - val_loss: 416.0684\n",
      "Epoch 26/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 414.3072 - val_loss: 408.6146\n",
      "Epoch 27/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 409.0374 - val_loss: 403.2409\n",
      "Epoch 28/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 403.5882 - val_loss: 398.1046\n",
      "Epoch 29/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 398.3186 - val_loss: 394.1727\n",
      "Epoch 30/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 394.7443 - val_loss: 390.4102\n",
      "Epoch 31/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 393.9972 - val_loss: 387.5775\n",
      "Epoch 32/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 387.1800 - val_loss: 385.2461\n",
      "Epoch 33/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 388.0193 - val_loss: 383.2858\n",
      "Epoch 34/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 384.8980 - val_loss: 381.8868\n",
      "Epoch 35/100\n",
      "14441/14441 [==============================] - 1s 39us/step - loss: 384.6151 - val_loss: 380.8422\n",
      "Epoch 36/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 385.5192 - val_loss: 380.0355\n",
      "Epoch 37/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 380.8457 - val_loss: 378.9169\n",
      "Epoch 38/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 382.7503 - val_loss: 379.0873\n",
      "Epoch 39/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 380.6135 - val_loss: 378.4256\n",
      "Epoch 40/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 380.5828 - val_loss: 378.3472\n",
      "Epoch 41/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 378.5980 - val_loss: 377.7552\n",
      "Epoch 42/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 378.6674 - val_loss: 377.4921\n",
      "Epoch 43/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 379.5012 - val_loss: 377.2229\n",
      "Epoch 44/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 380.1368 - val_loss: 376.8312\n",
      "Epoch 45/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 376.8326 - val_loss: 376.9020\n",
      "Epoch 46/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 379.5450 - val_loss: 376.6908\n",
      "Epoch 47/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 378.7650 - val_loss: 376.3935\n",
      "Epoch 48/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 378.5096 - val_loss: 376.3317\n",
      "Epoch 49/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 377.1588 - val_loss: 375.9379\n",
      "Epoch 50/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 379.2083 - val_loss: 375.5190\n",
      "Epoch 51/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 377.4699 - val_loss: 376.1912\n",
      "Epoch 52/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 376.8925 - val_loss: 375.5313\n",
      "Epoch 53/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 378.1912 - val_loss: 375.3878\n",
      "Epoch 54/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 377.6136 - val_loss: 375.4432\n",
      "Epoch 55/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 376.5563 - val_loss: 375.1014\n",
      "Epoch 56/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 377.6028 - val_loss: 374.9600\n",
      "Epoch 57/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 377.0196 - val_loss: 375.2473\n",
      "Epoch 58/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 376.4561 - val_loss: 375.1720\n",
      "Epoch 59/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 377.5283 - val_loss: 374.6796\n",
      "Epoch 60/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 375.2622 - val_loss: 374.5243\n",
      "Epoch 61/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 377.3640 - val_loss: 373.9311\n",
      "Epoch 62/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 375.5843 - val_loss: 374.0012\n",
      "Epoch 63/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 375.1957 - val_loss: 373.8082\n",
      "Epoch 64/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 375.8500 - val_loss: 373.3562\n",
      "Epoch 65/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 374.3385 - val_loss: 373.2996\n",
      "Epoch 66/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 376.0656 - val_loss: 373.3647\n",
      "Epoch 67/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 374.1413 - val_loss: 372.9589\n",
      "Epoch 68/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 374.1334 - val_loss: 373.1117\n",
      "Epoch 69/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 375.5775 - val_loss: 372.7035\n",
      "Epoch 70/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 373.7906 - val_loss: 372.3670\n",
      "Epoch 71/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 372.6875 - val_loss: 372.1471\n",
      "Epoch 72/100\n",
      "14441/14441 [==============================] - 1s 39us/step - loss: 373.1852 - val_loss: 372.0887\n",
      "Epoch 73/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 374.3747 - val_loss: 371.6678\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14441/14441 [==============================] - 1s 37us/step - loss: 372.7930 - val_loss: 371.7024\n",
      "Epoch 75/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 372.8509 - val_loss: 371.4216\n",
      "Epoch 76/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 372.5968 - val_loss: 371.9724\n",
      "Epoch 77/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 373.0788 - val_loss: 371.5622\n",
      "Epoch 78/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 373.5462 - val_loss: 371.1177\n",
      "Epoch 79/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 371.2497 - val_loss: 371.0328\n",
      "Epoch 80/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 371.1620 - val_loss: 370.8323\n",
      "Epoch 81/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 372.5953 - val_loss: 370.5434\n",
      "Epoch 82/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 370.9308 - val_loss: 370.4181\n",
      "Epoch 83/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 370.3668 - val_loss: 370.2328\n",
      "Epoch 84/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 370.6744 - val_loss: 369.6375\n",
      "Epoch 85/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 369.2897 - val_loss: 369.6230\n",
      "Epoch 86/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 369.4016 - val_loss: 369.2901\n",
      "Epoch 87/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 370.1749 - val_loss: 369.2927\n",
      "Epoch 88/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 370.0940 - val_loss: 369.2409\n",
      "Epoch 89/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 369.1856 - val_loss: 368.6858\n",
      "Epoch 90/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 368.6569 - val_loss: 368.7723\n",
      "Epoch 91/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 370.2383 - val_loss: 369.1607\n",
      "Epoch 92/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 368.5402 - val_loss: 368.1618\n",
      "Epoch 93/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 367.8916 - val_loss: 367.8991\n",
      "Epoch 94/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 368.0262 - val_loss: 367.5497\n",
      "Epoch 95/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 368.6225 - val_loss: 367.6358\n",
      "Epoch 96/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 368.6946 - val_loss: 367.3855\n",
      "Epoch 97/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 367.9337 - val_loss: 367.8309\n",
      "Epoch 98/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 367.7001 - val_loss: 367.3045\n",
      "Epoch 99/100\n",
      "14441/14441 [==============================] - 1s 37us/step - loss: 367.3189 - val_loss: 367.3177\n",
      "Epoch 100/100\n",
      "14441/14441 [==============================] - 1s 38us/step - loss: 367.0240 - val_loss: 367.2654\n",
      "Training time: 2.595 minutes\n"
     ]
    }
   ],
   "source": [
    "#10个epoch loss不下降，就降低学习率\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, mode='auto')\n",
    "start_time = time.clock()\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[reduce_lr],\n",
    "    verbose=1,\n",
    "    shuffle=False)  #shuffle=False比True时测试集rmse降低了1\n",
    "end_time = time.clock()\n",
    "print(\"Training time: {:.4} minutes\".format((end_time - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val') \n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions,targets):\n",
    "    return np.sqrt(((predictions-targets)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rmse = rmse(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rmse: 19.157870142395726\n",
      "Validation rmse: 19.16417022078463\n",
      "Test rmse: 57.22915452320545\n"
     ]
    }
   ],
   "source": [
    "print(\"Train rmse: {}\".format(np.sqrt(history.history['loss'][-1])))\n",
    "print(\"Validation rmse: {}\".format(np.sqrt(history.history['val_loss'][-1])))\n",
    "print(\"Test rmse: {}\".format(my_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加入PCA降维和自动学习率下降后，精度大大提升**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_2 (Bidirection (None, 100)               27200     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 32,301\n",
      "Trainable params: 32,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "689px",
    "left": "25px",
    "top": "180px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "931px",
    "right": "20px",
    "top": "21px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
